---
title: 'MuTT: A Multimodal Trajectory Transformer for Robot Skills'
collection: publications
permalink: /publication/mutt
date: 2024-07-30
venue: 'IROS'
authors: 'Claudius Kienle, Benjamin Alt, <b>Onur Celik</b>, Philipp Becker, Darko Katic, Rainer JÃ¤kel, Gerhard Neumann'
paperurl: 'https://arxiv.org/pdf/2407.15660'
#codeurl: 'https://alrhub.github.io/di-skill-website/'
tag: "rl"
#slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
#paperurl: 'http://academicpages.github.io/files/paper1.pdf'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

<p>
<h3> Abstract: </h3>
High-level robot skills represent an increasingly popular paradigm in robot programming. However, configuring the skills' parameters for a specific task remains a manual and time-consuming endeavor. Existing approaches for learning or optimizing these parameters often require numerous real-world executions or do not work in dynamic environments. To address these challenges, we propose MuTT, a novel encoder-decoder transformer architecture designed to predict environment-aware executions of robot skills by integrating vision, trajectory, and robot skill parameters. Notably, we pioneer the fusion of vision and trajectory, introducing a novel trajectory projection. Furthermore, we illustrate MuTT's efficacy as a predictor when combined with a model-based robot skill optimizer. This approach facilitates the optimization of robot skill parameters for the current environment, without the need for real-world executions during optimization. Designed for compatibility with any representation of robot skills, MuTT demonstrates its versatility across three comprehensive experiments, showcasing superior performance across two different skill representations.</p>